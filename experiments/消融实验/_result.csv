"说明：
1.模型的*表示推理阶段用的是之前SCOPE的方式。所以每个指标实际上可以再增加一点，大概0.2%左右
2. epoch为 “得出该结论的epoch”|“总的训练epoch”
",,,,,,,,,,,
,,,,,,,,,,,
说明：按照val_loss最低的进行统计,,,,,,,,,,,
模型,d_acc,d_pre,d_rec,d_f1,c_acc,c_pre,c_rec,c_f1,epoch,模型说明,其他说明
FULL*,0.8309,0.8645,0.7782,0.8191,0.82,0.8611,0.756,0.8051,6|11,全部组件,
wo_pinyin,0.8173,0.8571,0.7542,0.8024,0.8109,0.855,0.7412,0.7941,6|11,去掉拼音组件,
wo_py_em,0.8318,0.8739,0.7689,0.8181,0.8282,0.8729,0.7616,0.8134,6|11,同时去掉拼音和token embeddings融合,
wo_glyph_em,0.8391,0.8684,0.793,0.829,0.8245,0.864,0.7634,0.8106,4|9,同时去掉字形和token embeddings,
new_ft,0.8173,0.8441,0.7708,0.8058,0.8091,0.8412,0.7542,0.7953,5|10,使用(1-t)*hidden+t*embedding的遗忘门,
wo_ft,0.8300 ,0.8598,0.7819,0.8190 ,0.8227,0.8574,0.7671,0.8098,7|12,去掉遗忘门,
new_glyph,0.8218,0.8586,0.7634,0.8082,0.8155,0.8565,0.7505,0.8000 ,6|11,使用AutoEncoder构造的字形编码器,
wo_mm*,0.8273,0.8710 ,0.7616,0.8126,0.8164,0.8677,0.7394,0.7984,4|9,去掉多模态,
wo_mm_em*,0.8245,0.8595 ,0.7689,0.8117,0.8127,0.8556,0.7449,0.7964,10|10,同时去掉多模态和融合token embeddings,
wo_mm_FL*,0.8345,0.8612 ,0.7911,0.8247,0.8191,0.8562,0.7597,0.8051,4|9,同时去掉多模态和FocalLoss,
wo_FL*,0.8245,0.8412,0.7930 ,0.8164,0.8136,0.8373,0.7708,0.8027,3|8,去掉FocalLoss,没有FocalLoss的话，Val_loss会比较高
wo_FixIdx*,0.8209,0.8613,0.7579,0.8063,0.8082,0.8571,0.7320 ,0.7896,4|9,去掉固定Index,
wo_em*,0.8273,0.8664,0.7671,0.8137,0.8118,0.8615,0.7357,0.7936,5|10,去掉融合token embedding,
,,,,,,,,,,,
,,,,,,,,,,,
说明：按照val_f1最高的进行统计,,,,,,,,,,,
模型,d_acc,d_pre,d_rec,d_f1,c_acc,c_pre,c_rec,c_f1,epoch,模型说明,
FULL*,0.8427,0.8786,0.7893,0.8315,0.8327,0.8758,0.7689,0.8189,10|11,全部组件,
wo_pinyin,0.8382,0.8773,0.78,0.8258,0.8309,0.8753,0.7652,0.8166,11|11,去掉拼音组件,
wo_py_em,0.8391,0.8824,0.7763,0.826,0.8336,0.8809,0.7652,0.819,11|11,同时去掉拼音和token embeddings融合,
wo_glyph_em,0.8355,0.8797,0.7708,0.8217,0.8255,0.8769,0.7505,0.8088,9|9,同时去掉字形和token embeddings,
new_ft,0.83,0.8657,0.7745,0.8176,0.8264,0.8646,0.7671,0.8129,10|10,使用(1-t)*hidden+t*embedding的遗忘门,
wo_ft,0.8382,0.8789,0.7782,0.8255,0.8327,0.8774,0.7671,0.8185,11|12,去掉遗忘门,
new_glyph,0.8364,0.8691,0.7856,0.8252,0.8309,0.8675,0.7745,0.8184,11|11,使用AutoEncoder构造的字形编码器,
wo_mm*,0.8418,0.8692 ,0.7985,0.8324,0.8291,0.8654,0.7726,0.8164,9|9,去掉多模态,
wo_mm_em*,0.8245,0.8595 ,0.7689,0.8117,0.8127,0.8556,0.7449,0.7964,10|10,同时去掉多模态和融合token embeddings,
wo_mm_FL*,0.8318,0.8532 ,0.7948,0.8230 ,0.8164,0.8480 ,0.7634,0.8035,8|9,同时去掉多模态和FocalLoss,
wo_FL*,0.81,0.8217,0.7837,0.8023,0.7982,0.8171,0.7597,0.7874,8|8,去掉FocalLoss,
wo_FixIdx*,0.8273,0.8695,0.7634,0.8130 ,0.8182,0.8667,0.7449 ,0.8012,9|9,去掉固定Index,
wo_em*,0.8445,0.8887,0.7819,0.8319,0.8336,0.8858,0.7597,0.8179,10|10,去掉融合token embedding,
,,,,,,,,,,,
,,,,,,,,,,,
说明：按照test_f1最高的进行统计,,,,,,,,,,,
模型,d_acc,d_pre,d_rec,d_f1,c_acc,c_pre,c_rec,c_f1,epoch,模型说明,
FULL*,0.8427,0.8786,0.7893,0.8315,0.8327,0.8758,0.7689,0.8189,10|11,全部组件,
wo_pinyin,0.8455,0.8857,0.7874,0.8337,0.84,0.8842,0.7763,0.8268,8|11,去掉拼音组件,
wo_py_em,0.8445,0.8919,0.7782,0.8312,0.8391,0.8906,0.7671,0.8242,10|11,同时去掉拼音和token embeddings融合,
wo_glyph_em,0.8418,0.8799,0.7856,0.8301,0.83,0.8766,0.7616,0.815,7|9,同时去掉字形和token embeddings,
new_ft,0.83,0.8657,0.7745,0.8176,0.8264,0.8646,0.7671,0.8129,10|10,使用(1-t)*hidden+t*embedding的遗忘门,
wo_ft,0.8382,0.8758,0.7819,0.8262,0.8345,0.8747,0.7745,0.8216,12|12,去掉遗忘门,
new_glyph,0.84,0.8763,0.7856,0.8285,0.8327,0.8742,0.7708,0.8193,10|11,使用AutoEncoder构造的字形编码器,
wo_mm*,0.8373,0.8649 ,0.7930 ,0.8274,0.8291,0.8624,0.7763,0.8171,5|9,去掉多模态,
wo_mm_em*,0.8327,0.8727 ,0.7726,0.8196,0.8236,0.8699,0.7542,0.8079,6|10,同时去掉多模态和融合token embeddings,
wo_mm_FL*,0.8309,0.8460 ,0.8022,0.8235,0.8173,0.8414,0.7745,0.8065,9|9,同时去掉多模态和FocalLoss,
wo_FL*,0.8245,0.8412,0.7930 ,0.8164,0.8136,0.8373,0.7708,0.8027,3|8,去掉FocalLoss,
wo_FixIdx*,0.84,0.8908,0.7689,0.8254 ,0.8291,0.8879,0.7468 ,0.8112,7|9,去掉固定Index,
wo_em*,0.8482,0.8864,0.7930 ,0.8371,0.8364,0.8832,0.7689,0.8221,9|10,去掉融合token embedding,
