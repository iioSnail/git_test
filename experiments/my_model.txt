模型：MacBert, 使用macbert作为backbone，macbert的head。加入了FocalLoss中的难易样本的权重。使用了orthogonal_初始化head，其中参数为gain=1。对输出进行了改造，如果该字没错，则固定输出的softmax的index为1，否则softmax就正常输出所在的index。bert的输出融合了一开始的embedding数据，即last_hidden_state += token_embeddings。对token_embedding增加了遗忘门后再加，遗忘门权重只使用了token_emebdding来计算。
执行情况：平均5分钟一个epoch，最后loss还在下降，感觉可以到86%。
2023-04-06 02:03:53,513 - NumExpr defaulting to 2 threads.
Epoch 0 Training: 100% 250/250 [03:45<00:00,  1.11it/s, loss=0.0944, c_precision=0.985, c_recall=0.266, c_f1_score=0.418]
Epoch 0 Validation: 100% 62/62 [00:29<00:00,  2.08it/s, loss=0.0487, c_precision=0.972, c_recall=0.292, c_f1_score=0.449]
2023-04-06 02:08:33,444 - Correction Precision: 0.9723889555810655, Recall: 0.291786743515745, F1-Score: 0.44887780513096
Epoch 1 Training: 100% 250/250 [03:58<00:00,  1.05it/s, loss=0.0791, c_precision=0.961, c_recall=0.411, c_f1_score=0.576]
Epoch 1 Validation: 100% 62/62 [00:28<00:00,  2.14it/s, loss=0.0371, c_precision=0.966, c_recall=0.436, c_f1_score=0.6]
2023-04-06 02:13:51,640 - Correction Precision: 0.965654952075906, Recall: 0.43551873198831575, F1-Score: 0.6002979141690922
Epoch 2 Training: 100% 250/250 [03:55<00:00,  1.06it/s, loss=0.0574, c_precision=0.958, c_recall=0.503, c_f1_score=0.66]
Epoch 2 Validation: 100% 62/62 [00:29<00:00,  2.10it/s, loss=0.0287, c_precision=0.957, c_recall=0.522, c_f1_score=0.676]
2023-04-06 02:18:29,626 - Correction Precision: 0.9570673712014814, Recall: 0.5219740634003883, F1-Score: 0.6755244750674293
Epoch 3 Training: 100% 250/250 [03:55<00:00,  1.06it/s, loss=0.0347, c_precision=0.948, c_recall=0.536, c_f1_score=0.684]
Epoch 3 Validation: 100% 62/62 [00:30<00:00,  2.06it/s, loss=0.0257, c_precision=0.933, c_recall=0.597, c_f1_score=0.728]
2023-04-06 02:23:08,976 - Correction Precision: 0.9329577464783476, Recall: 0.5965417867433009, F1-Score: 0.7277521419101581
Epoch 4 Training: 100% 250/250 [03:55<00:00,  1.06it/s, loss=0.0388, c_precision=0.949, c_recall=0.627, c_f1_score=0.755]
Epoch 4 Validation: 100% 62/62 [00:29<00:00,  2.11it/s, loss=0.021, c_precision=0.952, c_recall=0.624, c_f1_score=0.754]
2023-04-06 02:27:47,488 - Correction Precision: 0.9521452145209284, Recall: 0.6235590778095736, F1-Score: 0.7535916407926382
Epoch 5 Training: 100% 250/250 [03:58<00:00,  1.05it/s, loss=0.0372, c_precision=0.944, c_recall=0.639, c_f1_score=0.762]
Epoch 5 Validation: 100% 62/62 [00:29<00:00,  2.11it/s, loss=0.0204, c_precision=0.958, c_recall=0.637, c_f1_score=0.765]
2023-04-06 02:32:28,736 - Correction Precision: 0.9582429501079403, Recall: 0.6365273775213846, F1-Score: 0.7649350644550815
Epoch 6 Training: 100% 250/250 [03:58<00:00,  1.05it/s, loss=0.0267, c_precision=0.951, c_recall=0.662, c_f1_score=0.781]
Epoch 6 Validation: 100% 62/62 [00:29<00:00,  2.09it/s, loss=0.0169, c_precision=0.936, c_recall=0.686, c_f1_score=0.791]
2023-04-06 02:37:10,119 - Correction Precision: 0.9360550909980639, Recall: 0.6855187319882257, F1-Score: 0.7914327298089654
Epoch 7 Training: 100% 250/250 [03:54<00:00,  1.06it/s, loss=0.0245, c_precision=0.94, c_recall=0.672, c_f1_score=0.784]
Epoch 7 Validation: 100% 62/62 [00:29<00:00,  2.10it/s, loss=0.0173, c_precision=0.948, c_recall=0.696, c_f1_score=0.803]
2023-04-06 02:41:47,971 - Correction Precision: 0.9479882237483082, Recall: 0.6959654178671845, F1-Score: 0.8026589110195188
Epoch 8 Training: 100% 250/250 [03:56<00:00,  1.06it/s, loss=0.0259, c_precision=0.946, c_recall=0.691, c_f1_score=0.799]
Epoch 8 Validation: 100% 62/62 [00:28<00:00,  2.17it/s, loss=0.0159, c_precision=0.928, c_recall=0.702, c_f1_score=0.799]
2023-04-06 02:46:26,131 - Correction Precision: 0.927653498333685, Recall: 0.7020893371755396, F1-Score: 0.7992618408051286
Epoch 9 Training: 100% 250/250 [03:55<00:00,  1.06it/s, loss=0.0143, c_precision=0.946, c_recall=0.721, c_f1_score=0.819]
Epoch 9 Validation: 100% 62/62 [00:28<00:00,  2.16it/s, loss=0.0146, c_precision=0.941, c_recall=0.724, c_f1_score=0.818]
2023-04-06 02:51:03,021 - Correction Precision: 0.9409836065569364, Recall: 0.7237031700285578, F1-Score: 0.8181633063703312
Epoch 10 Training: 100% 250/250 [03:50<00:00,  1.08it/s, loss=0.0336, c_precision=0.941, c_recall=0.716, c_f1_score=0.813]
Epoch 10 Validation: 100% 62/62 [00:28<00:00,  2.15it/s, loss=0.0145, c_precision=0.946, c_recall=0.726, c_f1_score=0.822]
2023-04-06 02:55:35,786 - Correction Precision: 0.9455909943710387, Recall: 0.7262247838614099, F1-Score: 0.8215158919288117
Epoch 11 Training: 100% 250/250 [03:54<00:00,  1.07it/s, loss=0.016, c_precision=0.948, c_recall=0.717, c_f1_score=0.817]
Epoch 11 Validation: 100% 62/62 [00:28<00:00,  2.14it/s, loss=0.0127, c_precision=0.943, c_recall=0.743, c_f1_score=0.831]
2023-04-06 03:00:12,574 - Correction Precision: 0.943301326016944, Recall: 0.7431556195962741, F1-Score: 0.831352004342492
Epoch 12 Training: 100% 250/250 [04:00<00:00,  1.04it/s, loss=0.0372, c_precision=0.938, c_recall=0.725, c_f1_score=0.817]
Epoch 12 Validation: 100% 62/62 [00:29<00:00,  2.09it/s, loss=0.0123, c_precision=0.952, c_recall=0.747, c_f1_score=0.837]
2023-04-06 03:04:55,929 - Correction Precision: 0.9518127581455017, Recall: 0.7471181556193274, F1-Score: 0.8371342073777579
Epoch 13 Training: 100% 250/250 [03:58<00:00,  1.05it/s, loss=0.0165, c_precision=0.945, c_recall=0.748, c_f1_score=0.835]
Epoch 13 Validation: 100% 62/62 [00:29<00:00,  2.09it/s, loss=0.0106, c_precision=0.959, c_recall=0.751, c_f1_score=0.842]
2023-04-06 03:09:36,699 - Correction Precision: 0.9586016559333217, Recall: 0.7507204610948305, F1-Score: 0.842020201527257
Epoch 14 Training: 100% 250/250 [03:59<00:00,  1.04it/s, loss=0.00948, c_precision=0.933, c_recall=0.758, c_f1_score=0.837]
Epoch 14 Validation: 100% 62/62 [00:29<00:00,  2.10it/s, loss=0.0114, c_precision=0.952, c_recall=0.767, c_f1_score=0.85]
2023-04-06 03:14:18,784 - Correction Precision: 0.9517426273454193, Recall: 0.7672910662821444, F1-Score: 0.8496210605345361
Epoch 15 Training: 100% 250/250 [03:59<00:00,  1.05it/s, loss=0.0152, c_precision=0.95, c_recall=0.762, c_f1_score=0.846]
Epoch 15 Validation: 100% 62/62 [00:29<00:00,  2.13it/s, loss=0.0116, c_precision=0.952, c_recall=0.76, c_f1_score=0.845]
2023-04-06 03:19:00,009 - Correction Precision: 0.9517148014436139, Recall: 0.759726224783588, F1-Score: 0.8449519225828765
Epoch 16 Training: 100% 250/250 [03:57<00:00,  1.05it/s, loss=0.0124, c_precision=0.941, c_recall=0.761, c_f1_score=0.842]
Epoch 16 Validation: 100% 62/62 [00:28<00:00,  2.15it/s, loss=0.0123, c_precision=0.921, c_recall=0.785, c_f1_score=0.848]
2023-04-06 03:23:39,060 - Correction Precision: 0.9209970426696574, Recall: 0.7853025936596595, F1-Score: 0.8477542285520256
Epoch 17 Training: 100% 250/250 [03:51<00:00,  1.08it/s, loss=0.0137, c_precision=0.945, c_recall=0.78, c_f1_score=0.855]
Epoch 17 Validation: 100% 62/62 [00:28<00:00,  2.14it/s, loss=0.0114, c_precision=0.94, c_recall=0.776, c_f1_score=0.85]
2023-04-06 03:28:13,179 - Correction Precision: 0.9402268760903402, Recall: 0.7762968299709019, F1-Score: 0.8504340957946745
Epoch 18 Training: 100% 250/250 [03:55<00:00,  1.06it/s, loss=0.0113, c_precision=0.95, c_recall=0.783, c_f1_score=0.859]
Epoch 18 Validation: 100% 62/62 [00:29<00:00,  2.12it/s, loss=0.0113, c_precision=0.944, c_recall=0.782, c_f1_score=0.856]
2023-04-06 03:32:51,380 - Correction Precision: 0.944347826086546, Recall: 0.7824207492792571, F1-Score: 0.8557919616790006
Epoch 19 Training: 100% 250/250 [03:56<00:00,  1.06it/s, loss=0.00973, c_precision=0.944, c_recall=0.79, c_f1_score=0.86]
Epoch 19 Validation: 100% 62/62 [00:29<00:00,  2.12it/s, loss=0.00987, c_precision=0.955, c_recall=0.781, c_f1_score=0.86]
2023-04-06 03:37:30,876 - Correction Precision: 0.9550858652571752, Recall: 0.7813400576366062, F1-Score: 0.8595205067366842
Epoch 20 Training: 100% 250/250 [03:45<00:00,  1.11it/s, loss=0.02, c_precision=0.95, c_recall=0.802, c_f1_score=0.87]
Epoch 20 Validation: 100% 62/62 [00:27<00:00,  2.28it/s, loss=0.00986, c_precision=0.954, c_recall=0.78, c_f1_score=0.859]
2023-04-06 07:43:50,171 - Correction Precision: 0.9541850220260114, Recall: 0.7802593659939553, F1-Score: 0.8585017830956507
Epoch 21 Training: 100% 250/250 [03:55<00:00,  1.06it/s, loss=0.00615, c_precision=0.957, c_recall=0.829, c_f1_score=0.889]
Epoch 21 Validation: 100% 62/62 [00:27<00:00,  2.25it/s, loss=0.00983, c_precision=0.954, c_recall=0.782, c_f1_score=0.86]
2023-04-06 07:48:27,351 - Correction Precision: 0.9542857142852949, Recall: 0.7820605187317068, F1-Score: 0.8596317555924821
Epoch 22 Training: 100% 250/250 [03:54<00:00,  1.07it/s, loss=0.0183, c_precision=0.948, c_recall=0.82, c_f1_score=0.88]
Epoch 22 Validation: 100% 62/62 [00:26<00:00,  2.33it/s, loss=0.00948, c_precision=0.952, c_recall=0.79, c_f1_score=0.864]
2023-04-06 07:53:01,884 - Correction Precision: 0.9522362136339765, Recall: 0.7899855907778134, F1-Score: 0.8635558175784205
Epoch 23 Training: 100% 250/250 [03:54<00:00,  1.07it/s, loss=0.00536, c_precision=0.949, c_recall=0.825, c_f1_score=0.883]
Epoch 23 Validation: 100% 62/62 [00:28<00:00,  2.19it/s, loss=0.0106, c_precision=0.947, c_recall=0.796, c_f1_score=0.865]
2023-04-06 07:57:38,668 - Correction Precision: 0.9468495499352992, Recall: 0.7957492795386183, F1-Score: 0.8647484825725145
Epoch 24 Training: 100% 250/250 [03:59<00:00,  1.04it/s, loss=0.01, c_precision=0.954, c_recall=0.84, c_f1_score=0.893]
Epoch 24 Validation: 100% 62/62 [00:27<00:00,  2.29it/s, loss=0.00892, c_precision=0.941, c_recall=0.799, c_f1_score=0.865]
2023-04-06 08:02:18,611 - Correction Precision: 0.9414509970297236, Recall: 0.7993515850141213, F1-Score: 0.8646015970093263
Epoch 25 Training: 100% 250/250 [03:59<00:00,  1.04it/s, loss=0.0105, c_precision=0.954, c_recall=0.836, c_f1_score=0.891]
Epoch 25 Validation: 100% 62/62 [00:26<00:00,  2.31it/s, loss=0.00892, c_precision=0.946, c_recall=0.786, c_f1_score=0.859]
2023-04-06 08:06:58,372 - Correction Precision: 0.9458170784564605, Recall: 0.7860230547547601, F1-Score: 0.8585481010187723
Epoch 26 Training: 100% 250/250 [03:58<00:00,  1.05it/s, loss=0.00812, c_precision=0.957, c_recall=0.825, c_f1_score=0.886]
Epoch 26 Validation: 100% 62/62 [00:28<00:00,  2.20it/s, loss=0.0096, c_precision=0.927, c_recall=0.801, c_f1_score=0.859]
2023-04-06 08:11:38,851 - Correction Precision: 0.9266360983739363, Recall: 0.8007925072043225, F1-Score: 0.8591304342849302
Epoch 27 Training: 100% 250/250 [03:57<00:00,  1.05it/s, loss=0.00821, c_precision=0.953, c_recall=0.833, c_f1_score=0.889]
Epoch 27 Validation: 100% 62/62 [00:27<00:00,  2.26it/s, loss=0.00952, c_precision=0.951, c_recall=0.802, c_f1_score=0.87]
2023-04-06 08:16:17,642 - Correction Precision: 0.9508966695128306, Recall: 0.8022334293945237, F1-Score: 0.8702618205270928
Epoch 28 Training: 100% 250/250 [03:58<00:00,  1.05it/s, loss=0.0119, c_precision=0.957, c_recall=0.849, c_f1_score=0.9]
Epoch 28 Validation: 100% 62/62 [00:26<00:00,  2.35it/s, loss=0.0099, c_precision=0.943, c_recall=0.794, c_f1_score=0.862]
2023-04-06 08:20:56,397 - Correction Precision: 0.9434931506845277, Recall: 0.7939481268008667, F1-Score: 0.8622848195346657
Epoch 29 Training: 100% 250/250 [03:57<00:00,  1.05it/s, loss=0.00623, c_precision=0.959, c_recall=0.843, c_f1_score=0.897]
Epoch 29 Validation: 100% 62/62 [00:28<00:00,  2.21it/s, loss=0.00919, c_precision=0.941, c_recall=0.803, c_f1_score=0.867]
2023-04-06 08:25:36,093 - Correction Precision: 0.9405314213408096, Recall: 0.8033141210371746, F1-Score: 0.8665241883506316
Epoch 30 Training: 100% 250/250 [03:54<00:00,  1.07it/s, loss=0.00847, c_precision=0.96, c_recall=0.854, c_f1_score=0.904]
Epoch 30 Validation: 100% 62/62 [00:27<00:00,  2.29it/s, loss=0.00968, c_precision=0.91, c_recall=0.816, c_f1_score=0.861]
2023-04-06 08:30:11,151 - Correction Precision: 0.9104057854556407, Recall: 0.8162824207489855, F1-Score: 0.8607787269465528
Epoch 31 Training: 100% 250/250 [03:57<00:00,  1.05it/s, loss=0.00848, c_precision=0.954, c_recall=0.831, c_f1_score=0.888]
Epoch 31 Validation: 100% 62/62 [00:27<00:00,  2.22it/s, loss=0.00855, c_precision=0.936, c_recall=0.812, c_f1_score=0.869]
2023-04-06 08:34:49,812 - Correction Precision: 0.9356312292354918, Recall: 0.8115994236308316, F1-Score: 0.8692129624651472
Epoch 32 Training: 100% 250/250 [04:01<00:00,  1.04it/s, loss=0.0167, c_precision=0.956, c_recall=0.85, c_f1_score=0.9]
Epoch 32 Validation: 100% 62/62 [00:27<00:00,  2.28it/s, loss=0.00827, c_precision=0.947, c_recall=0.804, c_f1_score=0.87]
2023-04-06 08:39:31,432 - Correction Precision: 0.9469664828167387, Recall: 0.8040345821322752, F1-Score: 0.8696668609875048
Epoch 33 Training: 100% 250/250 [04:04<00:00,  1.02it/s, loss=0.00477, c_precision=0.958, c_recall=0.861, c_f1_score=0.907]
Epoch 33 Validation: 100% 62/62 [00:28<00:00,  2.16it/s, loss=0.00779, c_precision=0.939, c_recall=0.809, c_f1_score=0.87]
2023-04-06 08:44:17,834 - Correction Precision: 0.9393812709026174, Recall: 0.8094380403455298, F1-Score: 0.8695820428460772
Epoch 34 Training: 100% 250/250 [04:07<00:00,  1.01it/s, loss=0.00292, c_precision=0.96, c_recall=0.865, c_f1_score=0.91]
Epoch 34 Validation: 100% 62/62 [00:28<00:00,  2.17it/s, loss=0.00845, c_precision=0.953, c_recall=0.811, c_f1_score=0.876]
2023-04-06 08:49:06,962 - Correction Precision: 0.9533898305080706, Recall: 0.8105187319881807, F1-Score: 0.8761682238020045
Epoch 35 Training: 100% 250/250 [04:06<00:00,  1.01it/s, loss=0.00462, c_precision=0.961, c_recall=0.867, c_f1_score=0.912]
Epoch 35 Validation: 100% 62/62 [00:28<00:00,  2.15it/s, loss=0.00844, c_precision=0.948, c_recall=0.809, c_f1_score=0.873]
2023-04-06 08:53:56,341 - Correction Precision: 0.9481012658223847, Recall: 0.8094380403455298, F1-Score: 0.8732996497165312
Epoch 36 Training: 100% 250/250 [04:06<00:00,  1.02it/s, loss=0.00438, c_precision=0.964, c_recall=0.862, c_f1_score=0.91]
Epoch 36 Validation: 100% 62/62 [00:28<00:00,  2.18it/s, loss=0.00889, c_precision=0.929, c_recall=0.82, c_f1_score=0.871]
2023-04-06 08:58:44,316 - Correction Precision: 0.92895059207802, Recall: 0.8195244956769382, F1-Score: 0.8708133966308116
Epoch 37 Training: 100% 250/250 [04:04<00:00,  1.02it/s, loss=0.00861, c_precision=0.958, c_recall=0.864, c_f1_score=0.909]
Epoch 37 Validation: 100% 62/62 [00:28<00:00,  2.15it/s, loss=0.00897, c_precision=0.945, c_recall=0.816, c_f1_score=0.876]
2023-04-06 09:03:31,416 - Correction Precision: 0.9453483521064058, Recall: 0.8162824207489855, F1-Score: 0.8760873762663118
Epoch 38 Training: 100% 250/250 [04:10<00:00,  1.00s/it, loss=0.00843, c_precision=0.958, c_recall=0.861, c_f1_score=0.907]
Epoch 38 Validation: 100% 62/62 [00:28<00:00,  2.15it/s, loss=0.0085, c_precision=0.938, c_recall=0.818, c_f1_score=0.874]
2023-04-06 09:08:24,019 - Correction Precision: 0.9376548307180274, Recall: 0.818083573486737, F1-Score: 0.8737976139690855
Epoch 39 Training: 100% 250/250 [04:10<00:00,  1.00s/it, loss=0.00641, c_precision=0.956, c_recall=0.865, c_f1_score=0.908]
Epoch 39 Validation: 100% 62/62 [00:28<00:00,  2.18it/s, loss=0.0089, c_precision=0.949, c_recall=0.809, c_f1_score=0.874]
2023-04-06 09:13:15,982 - Correction Precision: 0.9489020270266263, Recall: 0.8094380403455298, F1-Score: 0.8736391907936302
Eval情况：居然超过了之前所有的情况。到底怎么回事，bug？还是pytorch lightning确实牛逼，或者说MultiModalBert其反作用？
Character-level Detect Acc: 0.9854, P: 0.6273, R: 0.7397, F1: 0.6789
Character-level Correct Acc: 0.9847, P: 0.6166, R: 0.7070, F1: 0.6587
Sentence-level Detect Acc: 0.6609, P: 0.6803, R: 0.5860, F1: 0.6296
Sentence-level Correct Acc: 0.6509, P: 0.6725, R: 0.5656, F1: 0.6145


模型：MacBert, 使用macbert作为backbone，macbert的head。加入了FocalLoss中的难易样本的权重。使用了orthogonal_初始化head，其中参数为gain=1。对输出进行了改造，如果该字没错，则固定输出的softmax的index为1，否则softmax就正常输出所在的index。bert的输出融合了一开始的embedding数据，即last_hidden_state += token_embeddings。对token_embedding增加了遗忘门后再加，遗忘门权重只使用了token_emebdding来计算。
使用bf16混合精度
