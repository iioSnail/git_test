实验：1w Wang271K数据，8:2拆分，20epoch。看验证集Correction情况

baseline: 纯BERT（chinese-roberta-wwm-ext）
执行情况：花费1小时
Correction Precision: 0.05530088044822416, Recall: 0.1420560747663286, F1-Score: 0.07961032798921384
Correction Precision: 0.17577108881454528, Recall: 0.26503548748594224, F1-Score: 0.21136515927320912
Correction Precision: 0.24929044465464373, Recall: 0.29556926528317523, F1-Score: 0.2704644593444641
Correction Precision: 0.2969277215414141, Recall: 0.3124065769805096, F1-Score: 0.30447054488859465
Correction Precision: 0.3403013182673558, Recall: 0.33718977421154367, F1-Score: 0.3387384004747338
Correction Precision: 0.3632075471697399, Recall: 0.34516249533052945, F1-Score: 0.3539551805000651
Correction Precision: 0.4058879392211954, Recall: 0.39869402985067187, F1-Score: 0.402258823029376
Correction Precision: 0.45856052344593623, Recall: 0.4722066254912086, F1-Score: 0.4652835403022346
Correction Precision: 0.49203570803422153, Recall: 0.5248319641522544, F1-Score: 0.5079049592980612
Correction Precision: 0.5215438363000297, Recall: 0.5862004487657841, F1-Score: 0.5519852094672721
Correction Precision: 0.5429462966003378, Recall: 0.618406285072836, F1-Score: 0.578224748080934
Correction Precision: 0.5549999999999105, Recall: 0.6428171118997491, F1-Score: 0.5956894308191255
Correction Precision: 0.5656014132004873, Recall: 0.6583177570092227, F1-Score: 0.6084477839028679
Correction Precision: 0.5699383594119535, Recall: 0.6741446999437887, F1-Score: 0.617677286245437
Correction Precision: 0.5773519711008988, Recall: 0.6862049654656176, F1-Score: 0.627089729971021
Correction Precision: 0.5831769856159188, Recall: 0.6964152352500567, F1-Score: 0.6347855679176947
Correction Precision: 0.5861315008588808, Recall: 0.7012331838563711, F1-Score: 0.6385367923579929
Correction Precision: 0.5908596300325523, Recall: 0.7100691201194265, F1-Score: 0.6450025448969279
Correction Precision: 0.5956122607747634, Recall: 0.7147124719938919, F1-Score: 0.6497496388148921
Correction Precision: 0.6004063134863884, Recall: 0.71853375724692, F1-Score: 0.6541801459367275

模型：MultiModalBert，随便弄的，glyph和pinyin信息大概都是75%。
执行情况：花费2个多小时
Correction Precision: 0.0787985865724312, Recall: 0.16484938089074758, F1-Score: 0.10662841388307617
Correction Precision: 0.27237354085598064, Recall: 0.2715684463328521, F1-Score: 0.2719703972797843
Correction Precision: 0.40982763056331106, Recall: 0.2948362021098843, F1-Score: 0.34294940747879543
Correction Precision: 0.5084544645504276, Recall: 0.31693786982242655, F1-Score: 0.39047727484292544
Correction Precision: 0.5908529048205838, Recall: 0.3529628945910369, F1-Score: 0.4419276546801662
Correction Precision: 0.6726984126981992, Recall: 0.39153732446408135, F1-Score: 0.4949778084579314
Correction Precision: 0.7430615164518618, Recall: 0.47888622533644126, F1-Score: 0.5824175819408212
Correction Precision: 0.7909482758618559, Recall: 0.5426987060997148, F1-Score: 0.6437184823060457
Correction Precision: 0.8163057324838685, Recall: 0.5930038867294849, F1-Score: 0.6869639789292151
Correction Precision: 0.8420792079205837, Recall: 0.6290680473371617, F1-Score: 0.7201524127194746
Correction Precision: 0.8498334126604354, Recall: 0.6611738566930825, F1-Score: 0.7437259184912905
Correction Precision: 0.8599203560550808, Recall: 0.6779316712833466, F1-Score: 0.7581577855456724
Correction Precision: 0.8661710037172707, Recall: 0.6902425476762284, F1-Score: 0.768263781062129
Correction Precision: 0.8772663877264347, Recall: 0.6975970425137342, F1-Score: 0.7771828660631845
Correction Precision: 0.8764786169242773, Recall: 0.7119364375460621, F1-Score: 0.7856851544807353
Correction Precision: 0.8798098687186781, Recall: 0.7183515061909594, F1-Score: 0.790924813829899
Correction Precision: 0.886018581463656, Recall: 0.7231366746808353, F1-Score: 0.7963340117249199
Correction Precision: 0.8848728246316633, Recall: 0.7330868761551325, F1-Score: 0.8018600884650147
Correction Precision: 0.8909984364527828, Recall: 0.7376109467454257, F1-Score: 0.8070814360242516
Correction Precision: 0.8914067758580005, Recall: 0.7350601295095772, F1-Score: 0.8057189206157932


模型：MultiModalBert，和上面模型一样，但0.9*错字loss+0.1*复制字loss，相当于把侧重点放在改错字上
执行情况：召回率高，但精准率低。这是正常，因为模型不擅长复制原有字，而更偏向于改错，而且精准率还在不断增高。
Correction Precision: 0.02295154367417885, Recall: 0.3073369063019206, F1-Score: 0.04271330957427863
Correction Precision: 0.04886072495186621, Recall: 0.5954184370957702, F1-Score: 0.09031046836464413
Correction Precision: 0.06438301766259666, Recall: 0.6901721265962075, F1-Score: 0.11777897081765888
Correction Precision: 0.07666459482557539, Recall: 0.729844674556078, F1-Score: 0.13875413046143328
Correction Precision: 0.08979062767756905, Recall: 0.7544766475907781, F1-Score: 0.16048219245136672
Correction Precision: 0.10192293631644118, Recall: 0.7727272727271299, F1-Score: 0.1800917251348311
Correction Precision: 0.11395112560825321, Recall: 0.7859118569056267, F1-Score: 0.19904261507360302
Correction Precision: 0.126768450837063, Recall: 0.7950092421440305, F1-Score: 0.21866897124072388
Correction Precision: 0.13936375321336314, Recall: 0.802702202479955, F1-Score: 0.23749418149637494
Correction Precision: 0.15223974104625135, Recall: 0.8088017751477794, F1-Score: 0.25624652130691766
Correction Precision: 0.16423043852106006, Recall: 0.8133678948341393, F1-Score: 0.2732814927219945
Correction Precision: 0.17975105759843069, Recall: 0.8160664819943091, F1-Score: 0.2946098200314774
Correction Precision: 0.19391434350539996, Recall: 0.8165154600998302, F1-Score: 0.3133994240582174
Correction Precision: 0.20870137192256114, Recall: 0.8210720887244323, F1-Score: 0.3328088705841085
Correction Precision: 0.23079317321158735, Recall: 0.8220620842570543, F1-Score: 0.3604034181841296
Correction Precision: 0.250309162450801, Recall: 0.822953243392936, F1-Score: 0.38386276417831844
Correction Precision: 0.2649648934904043, Recall: 0.8235620491953349, F1-Score: 0.40093638823290406
Correction Precision: 0.2848558460653145, Recall: 0.8236598890941176, F1-Score: 0.42331259164772583
Correction Precision: 0.3037430967477805, Recall: 0.8237795857986642, F1-Score: 0.44383561604467403
Correction Precision: 0.3267508442225571, Recall: 0.8234967622570168, F1-Score: 0.46786145962368536

