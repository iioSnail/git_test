实验：1w Wang271K数据，8:2拆分，20epoch。看验证集Correction情况

baseline: 纯BERT（chinese-roberta-wwm-ext）
执行情况：花费1小时
Correction Precision: 0.05530088044822416, Recall: 0.1420560747663286, F1-Score: 0.07961032798921384
Correction Precision: 0.17577108881454528, Recall: 0.26503548748594224, F1-Score: 0.21136515927320912
Correction Precision: 0.24929044465464373, Recall: 0.29556926528317523, F1-Score: 0.2704644593444641
Correction Precision: 0.2969277215414141, Recall: 0.3124065769805096, F1-Score: 0.30447054488859465
Correction Precision: 0.3403013182673558, Recall: 0.33718977421154367, F1-Score: 0.3387384004747338
Correction Precision: 0.3632075471697399, Recall: 0.34516249533052945, F1-Score: 0.3539551805000651
Correction Precision: 0.4058879392211954, Recall: 0.39869402985067187, F1-Score: 0.402258823029376
Correction Precision: 0.45856052344593623, Recall: 0.4722066254912086, F1-Score: 0.4652835403022346
Correction Precision: 0.49203570803422153, Recall: 0.5248319641522544, F1-Score: 0.5079049592980612
Correction Precision: 0.5215438363000297, Recall: 0.5862004487657841, F1-Score: 0.5519852094672721
Correction Precision: 0.5429462966003378, Recall: 0.618406285072836, F1-Score: 0.578224748080934
Correction Precision: 0.5549999999999105, Recall: 0.6428171118997491, F1-Score: 0.5956894308191255
Correction Precision: 0.5656014132004873, Recall: 0.6583177570092227, F1-Score: 0.6084477839028679
Correction Precision: 0.5699383594119535, Recall: 0.6741446999437887, F1-Score: 0.617677286245437
Correction Precision: 0.5773519711008988, Recall: 0.6862049654656176, F1-Score: 0.627089729971021
Correction Precision: 0.5831769856159188, Recall: 0.6964152352500567, F1-Score: 0.6347855679176947
Correction Precision: 0.5861315008588808, Recall: 0.7012331838563711, F1-Score: 0.6385367923579929
Correction Precision: 0.5908596300325523, Recall: 0.7100691201194265, F1-Score: 0.6450025448969279
Correction Precision: 0.5956122607747634, Recall: 0.7147124719938919, F1-Score: 0.6497496388148921
Correction Precision: 0.6004063134863884, Recall: 0.71853375724692, F1-Score: 0.6541801459367275

模型：MultiModalBert，随便弄的，glyph和pinyin信息大概都是75%。
执行情况：花费2个多小时
Correction Precision: 0.0787985865724312, Recall: 0.16484938089074758, F1-Score: 0.10662841388307617
Correction Precision: 0.27237354085598064, Recall: 0.2715684463328521, F1-Score: 0.2719703972797843
Correction Precision: 0.40982763056331106, Recall: 0.2948362021098843, F1-Score: 0.34294940747879543
Correction Precision: 0.5084544645504276, Recall: 0.31693786982242655, F1-Score: 0.39047727484292544
Correction Precision: 0.5908529048205838, Recall: 0.3529628945910369, F1-Score: 0.4419276546801662
Correction Precision: 0.6726984126981992, Recall: 0.39153732446408135, F1-Score: 0.4949778084579314
Correction Precision: 0.7430615164518618, Recall: 0.47888622533644126, F1-Score: 0.5824175819408212
Correction Precision: 0.7909482758618559, Recall: 0.5426987060997148, F1-Score: 0.6437184823060457
Correction Precision: 0.8163057324838685, Recall: 0.5930038867294849, F1-Score: 0.6869639789292151
Correction Precision: 0.8420792079205837, Recall: 0.6290680473371617, F1-Score: 0.7201524127194746
Correction Precision: 0.8498334126604354, Recall: 0.6611738566930825, F1-Score: 0.7437259184912905
Correction Precision: 0.8599203560550808, Recall: 0.6779316712833466, F1-Score: 0.7581577855456724
Correction Precision: 0.8661710037172707, Recall: 0.6902425476762284, F1-Score: 0.768263781062129
Correction Precision: 0.8772663877264347, Recall: 0.6975970425137342, F1-Score: 0.7771828660631845
Correction Precision: 0.8764786169242773, Recall: 0.7119364375460621, F1-Score: 0.7856851544807353
Correction Precision: 0.8798098687186781, Recall: 0.7183515061909594, F1-Score: 0.790924813829899
Correction Precision: 0.886018581463656, Recall: 0.7231366746808353, F1-Score: 0.7963340117249199
Correction Precision: 0.8848728246316633, Recall: 0.7330868761551325, F1-Score: 0.8018600884650147
Correction Precision: 0.8909984364527828, Recall: 0.7376109467454257, F1-Score: 0.8070814360242516
Correction Precision: 0.8914067758580005, Recall: 0.7350601295095772, F1-Score: 0.8057189206157932


模型：MultiModalBert，和上面模型一样，但0.7*错字loss+0.3*复制字loss，相当于把侧重点放在改错字上
执行情况：召回率高，但精准率低。这是正常，因为模型不擅长复制原有字，而更偏向于改错，而且精准率还在不断增高。一共跑了30个epoch，这个方法有潜力。
Correction Precision: 0.02612711333750742, Recall: 0.30844575863975077, F1-Score: 0.048173644340866836
Correction Precision: 0.07302671033814474, Recall: 0.5848882320338842, F1-Score: 0.12984190108834653
Correction Precision: 0.11245818114851869, Recall: 0.678141773088899, F1-Score: 0.19292333589750169
Correction Precision: 0.14544098452358212, Recall: 0.7211538461537127, F1-Score: 0.24206312233493993
Correction Precision: 0.18556654061687614, Recall: 0.7518921912496304, F1-Score: 0.29766863960059764
Correction Precision: 0.22424209437760712, Recall: 0.7612712490759864, F1-Score: 0.3464368295832744
Correction Precision: 0.2640586797065849, Recall: 0.7766918679696152, F1-Score: 0.3941237013149178
Correction Precision: 0.2983320430712718, Recall: 0.7835489833639956, F1-Score: 0.4321321164260555
Correction Precision: 0.3451916829109531, Recall: 0.7866000370163266, F1-Score: 0.47981936169849404
Correction Precision: 0.37759663423609624, Recall: 0.7965976331359473, F1-Score: 0.5123387044455715
Correction Precision: 0.40329989687818474, Recall: 0.7965191631177936, F1-Score: 0.5354742340569981
Correction Precision: 0.44594177553745024, Recall: 0.8005540166203508, F1-Score: 0.5728065534515958
Correction Precision: 0.4702497285558664, Recall: 0.8018885391592664, F1-Score: 0.5928410097316956
Correction Precision: 0.49418604651157155, Recall: 0.8012939001846947, F1-Score: 0.6113383157034463
Correction Precision: 0.5258631132646243, Recall: 0.8021064301550623, F1-Score: 0.6352527982337695
Correction Precision: 0.5544352265474722, Recall: 0.8028090925890218, F1-Score: 0.6558961190999155
Correction Precision: 0.577132245655846, Recall: 0.804697614203661, F1-Score: 0.6721767336398277
Correction Precision: 0.6048699501936075, Recall: 0.8081330868760058, F1-Score: 0.6918816263499268
Correction Precision: 0.6271601382487576, Recall: 0.8052884615383126, F1-Score: 0.7051489632381874
Correction Precision: 0.6476984954564803, Recall: 0.804440333024828, F1-Score: 0.7176101661998809
Correction Precision: 0.6721109399074465, Recall: 0.8056889545620971, F1-Score: 0.7328629027297684
Correction Precision: 0.690891780387069, Recall: 0.8046571798187386, F1-Score: 0.7434474510523266
Correction Precision: 0.7055690072638086, Recall: 0.8072022160663329, F1-Score: 0.7529715757295172
Correction Precision: 0.7265611990007116, Recall: 0.8057248384116702, F1-Score: 0.7640980730563671
Correction Precision: 0.7463867859599541, Recall: 0.8025901942644212, F1-Score: 0.7734688414368668
Correction Precision: 0.7512454904654267, Recall: 0.8075715604799986, F1-Score: 0.7783908859369686
Correction Precision: 0.7648092810685946, Recall: 0.8041027536498236, F1-Score: 0.7839639634641362
Correction Precision: 0.7801075268815806, Recall: 0.8038781163433418, F1-Score: 0.7918144606186588
Correction Precision: 0.7958471150310922, Recall: 0.8001108442636615, F1-Score: 0.7979732837006855
Correction Precision: 0.8042632066726961, Recall: 0.8024782689105229, F1-Score: 0.8033697458431216

模型：MultiModalBert，将PinyinEmbeddings换成了手动Embedding（就是a=1,b=2这样），这样效果居然是最好的，中间不需要学习，而且在CSC任务上也表现更好。参数少了反而结果好了
执行情况：
Correction Precision: 0.07042019598072825, Recall: 0.15619819487932285, F1-Score: 0.09707515268249438
Correction Precision: 0.2600668190609706, Recall: 0.27302935203982404, F1-Score: 0.2663904894137923
Correction Precision: 0.40020237794070324, Recall: 0.2916666666666129, F1-Score: 0.3374213496242088
Correction Precision: 0.500737245650103, Recall: 0.31270718232038436, F1-Score: 0.3849903634309478
Correction Precision: 0.5763734518893057, Recall: 0.33468559837722023, F1-Score: 0.423471768083852
Correction Precision: 0.6475384132955009, Recall: 0.3806451612902524, F1-Score: 0.47945205432809934
Correction Precision: 0.7162503508277529, Recall: 0.47032805012892176, F1-Score: 0.5678050946376038
Correction Precision: 0.7764768493877657, Recall: 0.5375829034634234, F1-Score: 0.6353146087042816
Correction Precision: 0.8111111111109063, Recall: 0.5920737327187848, F1-Score: 0.6844965365392087
Correction Precision: 0.824282665401749, Recall: 0.642039157739076, F1-Score: 0.7218357382678269
Correction Precision: 0.8403361344535852, Recall: 0.6628613515005224, F1-Score: 0.7411219758320872
Correction Precision: 0.8546049555865229, Recall: 0.6734205194325523, F1-Score: 0.7532708349864256
Correction Precision: 0.8576642335764466, Recall: 0.6932153392329105, F1-Score: 0.7667210435511423
Correction Precision: 0.855849889624535, Recall: 0.7138648499354237, F1-Score: 0.7784358995139736
Correction Precision: 0.8692152917503086, Recall: 0.7172108467071172, F1-Score: 0.7859308666966691
Correction Precision: 0.8764019739791663, Recall: 0.7189915347808761, F1-Score: 0.789931257086592
Correction Precision: 0.8738079396760092, Recall: 0.7266691257837096, F1-Score: 0.7934749768477375
Correction Precision: 0.8858744394616846, Recall: 0.7278924097272056, F1-Score: 0.7991504849415232
Correction Precision: 0.8840035351301625, Recall: 0.7375115207371912, F1-Score: 0.8041402869122198
Correction Precision: 0.8906284454242798, Recall: 0.7446533923302461, F1-Score: 0.8111256145254097

模型：MultiModalBert，最后的cls层使用了3层的前馈神经网络。不更新bert的权重，只更新cls的权重
执行情况：学习速度偏慢，但是能学会，到第20次的时候还在增长。到40次，f1到48时就出现瓶颈了
Correction Precision: 0.008080127935358807, Recall: 0.07181597157283115, F1-Score: 0.014525921400909513
Correction Precision: 0.02605912257578512, Recall: 0.12936997569636766, F1-Score: 0.04338014014216185
Correction Precision: 0.06378037160552263, Recall: 0.20037418147797934, F1-Score: 0.09676107837064266
Correction Precision: 0.11207194742302731, Recall: 0.24251497005983483, F1-Score: 0.15330021248460957
Correction Precision: 0.17475394827189575, Recall: 0.2859550561797217, F1-Score: 0.2169342231404072
Correction Precision: 0.24415903811992837, Recall: 0.334143605085951, F1-Score: 0.2821504692365423
Correction Precision: 0.3196187450356919, Recall: 0.37642656688486875, F1-Score: 0.345704466857223
Correction Precision: 0.38469694292270984, Recall: 0.4072965388212521, F1-Score: 0.3956742997547881
Correction Precision: 0.4555619818776835, Recall: 0.44242651188907645, F1-Score: 0.448898175791815
Correction Precision: 0.5116422831237355, Recall: 0.4644594089037664, F1-Score: 0.48691048092081984
Correction Precision: 0.5555317783007584, Recall: 0.48568755846576506, F1-Score: 0.5182671186876124
Correction Precision: 0.5985742927153934, Recall: 0.5026187803964641, F1-Score: 0.5464158612220381
Correction Precision: 0.639269406392548, Recall: 0.5242463958059307, F1-Score: 0.5760724200376349
Correction Precision: 0.6728164409153029, Recall: 0.5395131086141312, F1-Score: 0.5988360003373486
Correction Precision: 0.689922480619993, Recall: 0.5499999999998969, F1-Score: 0.6120662702158364
Correction Precision: 0.7267139479903718, Recall: 0.5752245508980959, F1-Score: 0.6421558382365287
Correction Precision: 0.749217809867449, Recall: 0.5823045267488622, F1-Score: 0.6552994416717016
Correction Precision: 0.765828902851434, Recall: 0.5931124836233215, F1-Score: 0.6684948840137894
Correction Precision: 0.781679764243423, Recall: 0.5957327344187543, F1-Score: 0.6761550712030736
Correction Precision: 0.794430992735885, Recall: 0.613615111277237, F1-Score: 0.6924132104398286
再学20次：
Correction Precision: 0.8120740019472219, Recall: 0.6239012530389706, F1-Score: 0.7056583813170033
Correction Precision: 0.81771720613268, Recall: 0.6281547952887215, F1-Score: 0.7105096209929016
Correction Precision: 0.8236580034003342, Recall: 0.6344246959774303, F1-Score: 0.7167617834862875
Correction Precision: 0.836779372415267, Recall: 0.6437125748501789, F1-Score: 0.7276573236754563
Correction Precision: 0.840309702395151, Recall: 0.6503745318350841, F1-Score: 0.733241844752341
Correction Precision: 0.8455971049455137, Recall: 0.6553851907253823, F1-Score: 0.7384388491865846
Correction Precision: 0.853188929000998, Recall: 0.6632366697847215, F1-Score: 0.7463157889813723
Correction Precision: 0.8585907335905263, Recall: 0.6656688493918305, F1-Score: 0.7499209606207189
Correction Precision: 0.860687022900558, Recall: 0.6755289271670706, F1-Score: 0.7569495431974435
Correction Precision: 0.861961722487832, Recall: 0.6739618406283812, F1-Score: 0.7564560146238554
Correction Precision: 0.8667944417822551, Recall: 0.6768942937323336, F1-Score: 0.7601638822682009
Correction Precision: 0.8672714251609291, Recall: 0.6795735129067191, F1-Score: 0.7620346088412346
Correction Precision: 0.8678885979526617, Recall: 0.6826436996815797, F1-Score: 0.7642003767863729
Correction Precision: 0.8730385164049279, Recall: 0.6876404494380735, F1-Score: 0.7693274665087804
Correction Precision: 0.8734356552536308, Recall: 0.6926966292133534, F1-Score: 0.7726370752245133
Correction Precision: 0.8795352146073322, Recall: 0.6940494011974748, F1-Score: 0.7758602651693725
Correction Precision: 0.879461120302321, Recall: 0.6960344182565102, F1-Score: 0.7770700632008825
Correction Precision: 0.8794359576966205, Recall: 0.7003556054649633, F1-Score: 0.779745779877173
Correction Precision: 0.8804143126174951, Recall: 0.6999812839227587, F1-Score: 0.7798978203800905
Correction Precision: 0.8796816479398689, Recall: 0.7028240134653632, F1-Score: 0.7813702043090763
Correction Precision: 0.8834427767352524, Recall: 0.7045072002991014, F1-Score: 0.7838934549218551
Correction Precision: 0.8850198644541049, Recall: 0.7083800972688536, F1-Score: 0.7869090904150721

模型：MultiModalBert，最后的cls层使用了2层的Transformer。不更新bert的权重，只更新cls的权重
执行情况：比3层Dense层好，训练到40个epoch后效果和之前的差不都，虽然还在涨，但感觉涨不太动了。
Correction Precision: 0.0038887773172912956, Recall: 0.039335180055394395, F1-Score: 0.007077822658077036
Correction Precision: 0.024105629975382074, Recall: 0.13921713441651787, F1-Score: 0.041095516848798676
Correction Precision: 0.057618497109823925, Recall: 0.22993172171983206, F1-Score: 0.09214613190850107
Correction Precision: 0.09968827930173942, Recall: 0.29512735326683365, F1-Score: 0.14903532444308504
Correction Precision: 0.15292973498661536, Recall: 0.3481549815497512, F1-Score: 0.21251196533971026
Correction Precision: 0.2155562255049527, Recall: 0.3959025470652647, F1-Score: 0.2791333198635847
Correction Precision: 0.2769830949284458, Recall: 0.43260709010331744, F1-Score: 0.3377297292537307
Correction Precision: 0.3364661654134886, Recall: 0.4632162661736666, F1-Score: 0.3897962353190023
Correction Precision: 0.389415950192649, Recall: 0.4844182186980482, F1-Score: 0.43175281403455945
Correction Precision: 0.4398774983880658, Recall: 0.5035984498984123, F1-Score: 0.46958616486398264
Correction Precision: 0.48995708154498024, Recall: 0.527541589648701, F1-Score: 0.5080551841912904
Correction Precision: 0.5364394488758998, Recall: 0.5458402508761213, F1-Score: 0.5410990211695008
Correction Precision: 0.5791258477768313, Recall: 0.5675775480058036, F1-Score: 0.5732935466838304
Correction Precision: 0.6156694601441014, Recall: 0.5834872552640222, F1-Score: 0.599146514436235
Correction Precision: 0.6457336523124709, Recall: 0.5981532779315608, F1-Score: 0.6210334574624569
Correction Precision: 0.6777755060313477, Recall: 0.6121883656508564, F1-Score: 0.6433145735357106
Correction Precision: 0.6961712638944635, Recall: 0.6239852398522834, F1-Score: 0.6581046891296991
Correction Precision: 0.7156249999998509, Recall: 0.6338807898135017, F1-Score: 0.6722771303364224
Correction Precision: 0.7300420168065692, Recall: 0.6417359187441104, F1-Score: 0.6830466825486207
Correction Precision: 0.7457088366177694, Recall: 0.6499815293681843, F1-Score: 0.6945623206311995
Correction Precision: 0.7645429362879257, Recall: 0.6628486975797777, F1-Score: 0.7100732233298266
Correction Precision: 0.7773479475605464, Recall: 0.6679593721143734, F1-Score: 0.7185141035948945
Correction Precision: 0.7924691625187638, Recall: 0.6757704373499398, F1-Score: 0.7294820712161606
Correction Precision: 0.7993506493504763, Recall: 0.6811139800810252, F1-Score: 0.7355108539145143
Correction Precision: 0.8087277464175404, Recall: 0.6875230712438746, F1-Score: 0.7432162804289109
Correction Precision: 0.8178058336959473, Recall: 0.6931734317341894, F1-Score: 0.7503495101882929
Correction Precision: 0.8325285338013976, Recall: 0.6999446392322015, F1-Score: 0.7605012526364222
Correction Precision: 0.8353792196403254, Recall: 0.703915773919338, F1-Score: 0.7640336803374954
Correction Precision: 0.8404022737208481, Recall: 0.7096178696694277, F1-Score: 0.7694925427923656
Correction Precision: 0.8480349344976313, Recall: 0.7170020306441356, F1-Score: 0.7770331094363292
Correction Precision: 0.8517626450622177, Recall: 0.7177121771216387, F1-Score: 0.7790127160349823
Correction Precision: 0.8564530289725951, Recall: 0.7205909510617321, F1-Score: 0.7826697417560863
Correction Precision: 0.8593030900721325, Recall: 0.722631772944946, F1-Score: 0.7850635694304944
Correction Precision: 0.8635164835162936, Recall: 0.7245067305917896, F1-Score: 0.7879274034944482
Correction Precision: 0.8666959000217349, Recall: 0.7290667650312193, F1-Score: 0.7919463082283926
Correction Precision: 0.8686403508770024, Recall: 0.7310815799186542, F1-Score: 0.793946682205482
Correction Precision: 0.8735404274067253, Recall: 0.7318198597267014, F1-Score: 0.7964246253950694
Correction Precision: 0.8739864124477593, Recall: 0.736608792020551, F1-Score: 0.7994387085342481
Correction Precision: 0.8758741258739344, Recall: 0.7404396822463069, F1-Score: 0.8024827305074542
Correction Precision: 0.8809732573430773, Recall: 0.7411027106766105, F1-Score: 0.8050075107704568
Correction Precision: 0.8807017543857717, Recall: 0.7420546932740683, F1-Score: 0.8054552742728425
Correction Precision: 0.8846238694019667, Recall: 0.7406723309935831, F1-Score: 0.8062732477193024

模型：MDCSpell
执行情况：一开始效果炸裂，训练速度很快，一个epoch就能达到其他模型最好的效果，不过就没有后续了，再往后就越来越烂，最终early_stop了
Correction Precision: 0.9613157894734312, Recall: 0.6865250892688053, F1-Score: 0.8010086608447228
Correction Precision: 0.9573770491800864, Recall: 0.7127300037550295, F1-Score: 0.8171348612046657
Correction Precision: 0.896191966614268, Recall: 0.6448948948947738, F1-Score: 0.7500545727504156
Correction Precision: 0.8280214578728848, Recall: 0.49267743146817633, F1-Score: 0.6177751613920083
Correction Precision: 0.8746803069051472, Recall: 0.6417714392943062, F1-Score: 0.7403398631332385
Correction Precision: 0.888832997987704, Recall: 0.6636619718308612, F1-Score: 0.7599182878664451
Correction Precision: 0.9039735099335446, Recall: 0.6656039009751189, F1-Score: 0.7666882691160325
