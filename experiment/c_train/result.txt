实验：1w Wang271K数据，8:2拆分，20epoch。看验证集Correction情况

baseline: 纯BERT（chinese-roberta-wwm-ext）
执行情况：花费1小时
Correction Precision: 0.05530088044822416, Recall: 0.1420560747663286, F1-Score: 0.07961032798921384
Correction Precision: 0.17577108881454528, Recall: 0.26503548748594224, F1-Score: 0.21136515927320912
Correction Precision: 0.24929044465464373, Recall: 0.29556926528317523, F1-Score: 0.2704644593444641
Correction Precision: 0.2969277215414141, Recall: 0.3124065769805096, F1-Score: 0.30447054488859465
Correction Precision: 0.3403013182673558, Recall: 0.33718977421154367, F1-Score: 0.3387384004747338
Correction Precision: 0.3632075471697399, Recall: 0.34516249533052945, F1-Score: 0.3539551805000651
Correction Precision: 0.4058879392211954, Recall: 0.39869402985067187, F1-Score: 0.402258823029376
Correction Precision: 0.45856052344593623, Recall: 0.4722066254912086, F1-Score: 0.4652835403022346
Correction Precision: 0.49203570803422153, Recall: 0.5248319641522544, F1-Score: 0.5079049592980612
Correction Precision: 0.5215438363000297, Recall: 0.5862004487657841, F1-Score: 0.5519852094672721
Correction Precision: 0.5429462966003378, Recall: 0.618406285072836, F1-Score: 0.578224748080934
Correction Precision: 0.5549999999999105, Recall: 0.6428171118997491, F1-Score: 0.5956894308191255
Correction Precision: 0.5656014132004873, Recall: 0.6583177570092227, F1-Score: 0.6084477839028679
Correction Precision: 0.5699383594119535, Recall: 0.6741446999437887, F1-Score: 0.617677286245437
Correction Precision: 0.5773519711008988, Recall: 0.6862049654656176, F1-Score: 0.627089729971021
Correction Precision: 0.5831769856159188, Recall: 0.6964152352500567, F1-Score: 0.6347855679176947
Correction Precision: 0.5861315008588808, Recall: 0.7012331838563711, F1-Score: 0.6385367923579929
Correction Precision: 0.5908596300325523, Recall: 0.7100691201194265, F1-Score: 0.6450025448969279
Correction Precision: 0.5956122607747634, Recall: 0.7147124719938919, F1-Score: 0.6497496388148921
Correction Precision: 0.6004063134863884, Recall: 0.71853375724692, F1-Score: 0.6541801459367275

模型：MultiModalBert，随便弄的，glyph和pinyin信息大概都是75%。
执行情况：花费2个多小时
Correction Precision: 0.0787985865724312, Recall: 0.16484938089074758, F1-Score: 0.10662841388307617
Correction Precision: 0.27237354085598064, Recall: 0.2715684463328521, F1-Score: 0.2719703972797843
Correction Precision: 0.40982763056331106, Recall: 0.2948362021098843, F1-Score: 0.34294940747879543
Correction Precision: 0.5084544645504276, Recall: 0.31693786982242655, F1-Score: 0.39047727484292544
Correction Precision: 0.5908529048205838, Recall: 0.3529628945910369, F1-Score: 0.4419276546801662
Correction Precision: 0.6726984126981992, Recall: 0.39153732446408135, F1-Score: 0.4949778084579314
Correction Precision: 0.7430615164518618, Recall: 0.47888622533644126, F1-Score: 0.5824175819408212
Correction Precision: 0.7909482758618559, Recall: 0.5426987060997148, F1-Score: 0.6437184823060457
Correction Precision: 0.8163057324838685, Recall: 0.5930038867294849, F1-Score: 0.6869639789292151
Correction Precision: 0.8420792079205837, Recall: 0.6290680473371617, F1-Score: 0.7201524127194746
Correction Precision: 0.8498334126604354, Recall: 0.6611738566930825, F1-Score: 0.7437259184912905
Correction Precision: 0.8599203560550808, Recall: 0.6779316712833466, F1-Score: 0.7581577855456724
Correction Precision: 0.8661710037172707, Recall: 0.6902425476762284, F1-Score: 0.768263781062129
Correction Precision: 0.8772663877264347, Recall: 0.6975970425137342, F1-Score: 0.7771828660631845
Correction Precision: 0.8764786169242773, Recall: 0.7119364375460621, F1-Score: 0.7856851544807353
Correction Precision: 0.8798098687186781, Recall: 0.7183515061909594, F1-Score: 0.790924813829899
Correction Precision: 0.886018581463656, Recall: 0.7231366746808353, F1-Score: 0.7963340117249199
Correction Precision: 0.8848728246316633, Recall: 0.7330868761551325, F1-Score: 0.8018600884650147
Correction Precision: 0.8909984364527828, Recall: 0.7376109467454257, F1-Score: 0.8070814360242516
Correction Precision: 0.8914067758580005, Recall: 0.7350601295095772, F1-Score: 0.8057189206157932


模型：MultiModalBert，和上面模型一样，但0.7*错字loss+0.3*复制字loss，相当于把侧重点放在改错字上
执行情况：召回率高，但精准率低。这是正常，因为模型不擅长复制原有字，而更偏向于改错，而且精准率还在不断增高。一共跑了30个epoch，这个方法有潜力。
Correction Precision: 0.02612711333750742, Recall: 0.30844575863975077, F1-Score: 0.048173644340866836
Correction Precision: 0.07302671033814474, Recall: 0.5848882320338842, F1-Score: 0.12984190108834653
Correction Precision: 0.11245818114851869, Recall: 0.678141773088899, F1-Score: 0.19292333589750169
Correction Precision: 0.14544098452358212, Recall: 0.7211538461537127, F1-Score: 0.24206312233493993
Correction Precision: 0.18556654061687614, Recall: 0.7518921912496304, F1-Score: 0.29766863960059764
Correction Precision: 0.22424209437760712, Recall: 0.7612712490759864, F1-Score: 0.3464368295832744
Correction Precision: 0.2640586797065849, Recall: 0.7766918679696152, F1-Score: 0.3941237013149178
Correction Precision: 0.2983320430712718, Recall: 0.7835489833639956, F1-Score: 0.4321321164260555
Correction Precision: 0.3451916829109531, Recall: 0.7866000370163266, F1-Score: 0.47981936169849404
Correction Precision: 0.37759663423609624, Recall: 0.7965976331359473, F1-Score: 0.5123387044455715
Correction Precision: 0.40329989687818474, Recall: 0.7965191631177936, F1-Score: 0.5354742340569981
Correction Precision: 0.44594177553745024, Recall: 0.8005540166203508, F1-Score: 0.5728065534515958
Correction Precision: 0.4702497285558664, Recall: 0.8018885391592664, F1-Score: 0.5928410097316956
Correction Precision: 0.49418604651157155, Recall: 0.8012939001846947, F1-Score: 0.6113383157034463
Correction Precision: 0.5258631132646243, Recall: 0.8021064301550623, F1-Score: 0.6352527982337695
Correction Precision: 0.5544352265474722, Recall: 0.8028090925890218, F1-Score: 0.6558961190999155
Correction Precision: 0.577132245655846, Recall: 0.804697614203661, F1-Score: 0.6721767336398277
Correction Precision: 0.6048699501936075, Recall: 0.8081330868760058, F1-Score: 0.6918816263499268
Correction Precision: 0.6271601382487576, Recall: 0.8052884615383126, F1-Score: 0.7051489632381874
Correction Precision: 0.6476984954564803, Recall: 0.804440333024828, F1-Score: 0.7176101661998809
Correction Precision: 0.6721109399074465, Recall: 0.8056889545620971, F1-Score: 0.7328629027297684
Correction Precision: 0.690891780387069, Recall: 0.8046571798187386, F1-Score: 0.7434474510523266
Correction Precision: 0.7055690072638086, Recall: 0.8072022160663329, F1-Score: 0.7529715757295172
Correction Precision: 0.7265611990007116, Recall: 0.8057248384116702, F1-Score: 0.7640980730563671
Correction Precision: 0.7463867859599541, Recall: 0.8025901942644212, F1-Score: 0.7734688414368668
Correction Precision: 0.7512454904654267, Recall: 0.8075715604799986, F1-Score: 0.7783908859369686
Correction Precision: 0.7648092810685946, Recall: 0.8041027536498236, F1-Score: 0.7839639634641362
Correction Precision: 0.7801075268815806, Recall: 0.8038781163433418, F1-Score: 0.7918144606186588
Correction Precision: 0.7958471150310922, Recall: 0.8001108442636615, F1-Score: 0.7979732837006855
Correction Precision: 0.8042632066726961, Recall: 0.8024782689105229, F1-Score: 0.8033697458431216

模型：MultiModalBert，将PinyinEmbeddings换成了手动Embedding（就是a=1,b=2这样），这样效果居然是最好的，中间不需要学习，而且在CSC任务上也表现更好。参数少了反而结果好了
执行情况：
Correction Precision: 0.07042019598072825, Recall: 0.15619819487932285, F1-Score: 0.09707515268249438
Correction Precision: 0.2600668190609706, Recall: 0.27302935203982404, F1-Score: 0.2663904894137923
Correction Precision: 0.40020237794070324, Recall: 0.2916666666666129, F1-Score: 0.3374213496242088
Correction Precision: 0.500737245650103, Recall: 0.31270718232038436, F1-Score: 0.3849903634309478
Correction Precision: 0.5763734518893057, Recall: 0.33468559837722023, F1-Score: 0.423471768083852
Correction Precision: 0.6475384132955009, Recall: 0.3806451612902524, F1-Score: 0.47945205432809934
Correction Precision: 0.7162503508277529, Recall: 0.47032805012892176, F1-Score: 0.5678050946376038
Correction Precision: 0.7764768493877657, Recall: 0.5375829034634234, F1-Score: 0.6353146087042816
Correction Precision: 0.8111111111109063, Recall: 0.5920737327187848, F1-Score: 0.6844965365392087
Correction Precision: 0.824282665401749, Recall: 0.642039157739076, F1-Score: 0.7218357382678269
Correction Precision: 0.8403361344535852, Recall: 0.6628613515005224, F1-Score: 0.7411219758320872
Correction Precision: 0.8546049555865229, Recall: 0.6734205194325523, F1-Score: 0.7532708349864256
Correction Precision: 0.8576642335764466, Recall: 0.6932153392329105, F1-Score: 0.7667210435511423
Correction Precision: 0.855849889624535, Recall: 0.7138648499354237, F1-Score: 0.7784358995139736
Correction Precision: 0.8692152917503086, Recall: 0.7172108467071172, F1-Score: 0.7859308666966691
Correction Precision: 0.8764019739791663, Recall: 0.7189915347808761, F1-Score: 0.789931257086592
Correction Precision: 0.8738079396760092, Recall: 0.7266691257837096, F1-Score: 0.7934749768477375
Correction Precision: 0.8858744394616846, Recall: 0.7278924097272056, F1-Score: 0.7991504849415232
Correction Precision: 0.8840035351301625, Recall: 0.7375115207371912, F1-Score: 0.8041402869122198
Correction Precision: 0.8906284454242798, Recall: 0.7446533923302461, F1-Score: 0.8111256145254097